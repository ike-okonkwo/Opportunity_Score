{
 "metadata": {
  "name": "",
  "signature": "sha256:c04aa3f4a3ecfb6ec31fcf7ad84ac66c44fc0971db7e94136e51298e26a7ba25"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn import datasets  # used for synthetic data "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create Synthetic Data for training and prediction data pipelines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Notice that we have have two pipelines. The first pipeline generates data to train the model. The second pipeline is entirely new data we want to do predictions on. argument : n_samples controls the number of samples you want "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use this to build and train a model --> used for Stage 2 and Stage 3 \n",
      "build_model_pipeline = datasets.make_classification(n_samples = 10000)  \n",
      "\n",
      "# make prediction this data using trained model  --> input to Stage 4 \n",
      "prediction_pipeline = datasets.make_classification(n_samples = 1000)\n",
      "prediction_features = prediction_pipeline[0]\n",
      "actual_labels = prediction_pipeline[1] # used for testing \n",
      "object_ids = np.array([str(i) for i in xrange(1000)])\n",
      "\n",
      "## concatenate feature set with object ids \n",
      "prediction_feature_set = np.c_[object_ids, prediction_features]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print prediction_feature_set.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 21)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# features and labels from Build Model Pipeline [Stage 2 and Stage 3]\n",
      "feature_data = build_model_pipeline[0]\n",
      "label_data = build_model_pipeline[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_data.shape\n",
      "print label_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10000, 20)\n",
        "(10000,)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this point in the pipeline lets revert to two pipeline structure we had earlier. If you notice the input data to the\n",
      "connectors are named feature_data and label_data which is what you should also have in your code. The parts of the code that are commented don't apply to this synthetic data we are using"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# for i in cat_feature_data.columns:\n",
      "#     #print i\n",
      "#     temp_df = pd.get_dummies(cat_feature_data[str(i)])\n",
      "#     feature_data = feature_data.join(temp_df, rsuffix=i)\n",
      "#     temp_df = pd.DataFrame()  # clear dataframe\n",
      "    \n",
      "    \n",
      "# impute categorical variables \n",
      "from sklearn.preprocessing import Imputer\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "# define impute pipeline\n",
      "imputer_nan = Imputer(strategy='most_frequent', missing_values='NaN', axis=0)\n",
      "imputer_null = Imputer(strategy='median', missing_values=0, axis=0)\n",
      "\n",
      "impute_pipeline = Pipeline([\n",
      "    ('imp_null', imputer_null),\n",
      "    ('imp_nan', imputer_nan),\n",
      "])\n",
      "\n",
      "impute_pipeline_label = Pipeline([\n",
      "    ('imp_nan', imputer_nan),\n",
      "])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # get labels\n",
      "# label_data = feature_data[['predictor']]\n",
      " \n",
      "# # drop target feature\n",
      "# feature_data.drop('predictor', axis = 1, inplace = True)\n",
      " \n",
      "# feature_data.reset_index(drop=True, inplace=True)\n",
      "# label_data.reset_index(drop=True, inplace=True)\n",
      " \n",
      "feature_data_impute = impute_pipeline.fit_transform(feature_data)\n",
      "label_data_impute = impute_pipeline_label.fit_transform(label_data)\n",
      "label_data_impute = label_data_impute.T\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_data_impute.shape\n",
      "print label_data_impute.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10000, 20)\n",
        "(10000, 1)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# split train and test data\n",
      "# Once spilt, the Test and Train data are sent to next stage  - Stage 2\n",
      "from sklearn.cross_validation import train_test_split\n",
      "feature_train, feature_test, label_train, label_test = train_test_split(feature_data_impute, label_data_impute, test_size=0.3, random_state=42)\n",
      " \n",
      "label_test = label_test.ravel()\n",
      "label_train = label_train.ravel()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print feature_train.shape\n",
      "print feature_test.shape\n",
      "print label_train.shape\n",
      "print label_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(7000, 20)\n",
        "(3000, 20)\n",
        "(7000,)\n",
        "(3000,)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> This data : feature_train, feature_test, label_train, label_test is then sent to Stage 2 [Train / Test]. We then choose the best model and send that best model and all the data (feature_data_impute, label_data_impute)  to Stage 3 [Fully Train]. The output from Stage 3 is a model trained on all the data which is input to Stage 4. The data (features) we use in Stage 2 and Stage 3 don't have any object_id information. Only the data sent to Stage 4 has the object_id information becasue it is coming from a different pipeline"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> For the predict function, it should be in this form below. The inputs are the trained model from Stage 3 and feature_set ( prediction_feature_set) in this case"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make predictions\n",
      "def predict(feature_set, model_obj, get_probas = False, prediction_set = False):\n",
      "    ''' \n",
      "    Stage 2 and Stage 3 usage :\n",
      "    predict(feature_set, model_obj, get_probas = False, prediction_set = False)\n",
      "    predict(feature_set, model_obj, get_probas = True, prediction_set = False)\n",
      "\n",
      "    Stage 4 usage : \n",
      "    predict(feature_set, model_obj, get_probas = False, prediction_set = True)\n",
      "    predict(feature_set, model_obj, get_probas = True, prediction_set = True)\n",
      "\n",
      "\n",
      "    Perform predictions on a new set of data given an already trained model \n",
      "    Classification : For classification problems the output will just be the class the instance belongs to\n",
      "    Regression : For regression problems the output will be a continuous variable (float/int)\n",
      "    To output probabilities / likelihoods use get_probas = True . The output here \n",
      "    will be a numpy array of dimension (N by n) where N is the number of obeservations in the \n",
      "    prediction set and n is the number of unique clases in the data.]\n",
      "\n",
      "    Assumption : the data in the prediction feature set has one extra column that holds an object_id or identifier_id that\n",
      "    basically identifies that prediction instance. This object_id / identifier_id will typically be the first column of the \n",
      "    prediction feature set.\n",
      "    To do predictions we will ignore this first column by using feature_set[:,1:]. After you have predictions you can recombine \n",
      "    your predictions and the identifier_id column by using c_[feature_set[:,1], feature_set[:,1:]]\n",
      "    object_id / identifier_id = feature_set[:,1]\n",
      "    '''\n",
      "    object_id = feature_set[:,:1]\n",
      "\n",
      "    if get_probas:\n",
      "        if prediction_set:\n",
      "            return object_id, model_obj.predict_proba(feature_set[:,1:])\n",
      "        else:\n",
      "            return model_obj.predict_proba(feature_set) \n",
      "    else:\n",
      "        if prediction_set:\n",
      "            return object_id, model_obj.predict(feature_set[:,1:]) \n",
      "        else:\n",
      "            return model_obj.predict(feature_set)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing predicted reuslts "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(actual_labels == preds[:,1].astype(np.int)) / float(len(actual_labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "0.48899999999999999"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# actual_labels\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.externals import joblib \n",
      "preds = joblib.load('/Users/ike/Documents/model_test/synthetic_test_predic.pkl')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "preds[:,1][:30].astype(np.int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "array([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "actual_labels[:30]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "array([1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
        "       0, 1, 1, 0, 0, 0, 0])"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print Counter(actual_labels)\n",
      "print Counter(preds[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counter({0: 500, 1: 500})\n",
        "Counter({'0': 745, '1': 255})\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datasets.make_classification?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.classification_report(actual_labels, preds[:,1].astype(np.int))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.49      0.73      0.59       500\n",
        "          1       0.48      0.24      0.32       500\n",
        "\n",
        "avg / total       0.49      0.49      0.46      1000\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.confusion_matrix(actual_labels, preds[:,1].astype(np.int))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "array([[367, 133],\n",
        "       [378, 122]])"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "2.5e6 / 170"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "14705.882352941177"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(11e3  * 179) + (4e3 * 155)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 60,
       "text": [
        "2589000.0"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "3.5e3 * 179"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "626500.0"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}