{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Exploration - explotation technique\n",
      "\n",
      "- (1) they smoothly decrease the amount of exploring they do over time instead of requiring you to make a sudden jump and \n",
      "- (2) they focus your resources during exploration on the better options instead of wasting time on the inferior options that are over-explored during typical A/B testing\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Epsilion Greedy \n",
      "\n",
      "> The epsilon-Greedy algorithm explores by selecting from all of the arms completely at random. It makes one of these random exploratory decisions with probability epsilon\n",
      "\n",
      "- With probability 1 \u2013 epsilon, the epsilon-Greedy algorithm exploits the best known option.\n",
      "- With probability epsilon / 2, the epsilon-Greedy algorithm explores the best known option.\n",
      "- With probability epsilon / 2, the epsilon-Greedy algorithm explores the worst known option.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Softmax Annealing\n",
      "\n",
      "> The Softmax algorithm tries to cope with arms differing in estimated value by explicitly incorporating information about the reward rates of the available arms into its method for choosing which arm to select when it explores. The Softmax algorithm explores by randomly selecting from all of the available arms with probabilities that are more-or-less proportional to the estimated value of each of the arms. If the other arms are noticeably worse than the best arm, they\u2019re chosen with very low probability. If the arms all have similar values, they\u2019re each chosen nearly equally often."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "UCB1\n",
      "\n",
      "- The algorithm\u2019s default choice is to select the arm that currently has the highest estimated value.\n",
      "- The algorithm sometimes decides to explore and chooses an option that isn\u2019t the one that currently seems best:\n",
      "\n",
      "\n",
      "> UCB doesn\u2019t use randomness at all. Unlike epsilon-Greedy or Softmax, it\u2019s possible to know exactly how UCB will behave in any given situation. This can make it easier to reason about at times.\n",
      "UCB doesn\u2019t have any free parameters that you need to configure before you can deploy it. This is a major improvement if you\u2019re interested in running it in the wild, because it means that you can start to use UCB without having a clear sense of what you expect the world to behave like.\n",
      "Taken together, the use of an explicit measure of confidence, the absence of unnecessary randomness and the absence of configurable parameters makes UCB very compelling. UCB is also very easy to understand, so let\u2019s just present the algorithm and then we can continue to discuss it in more detail.\n",
      "\n",
      "> The answer is surprising and reveals why the curiosity bonus that UCB has can behave in an non-intuitive way: the little dips you see in this graph come from UCB backpedaling and experimenting with inferior arms because it comes to the conclusion that it knows too little about those arms. This backpedaling matters less and less over time, but it\u2019s always present in UCB\u2019s behavior, which means that UCB doesn\u2019t become a strictly greedy algorithm even if you have a huge amount of data.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to explicitly keeping track of our confidence in the estimated values of each arm, the UCB algorithm is special for two other reasons:\n",
      "UCB doesn\u2019t use randomness at all. Unlike epsilon-Greedy or Softmax, it\u2019s possible to know exactly how UCB will behave in any given situation. This can make it easier to reason about at times.\n",
      "UCB doesn\u2019t have any free parameters that you need to configure before you can deploy it. This is a major improvement if you\u2019re interested in running it in the wild, because it means that you can start to use UCB without having a clear sense of what you expect the world to behave like.\n",
      "Taken together, the use of an explicit measure of confidence, the absence of unnecessary randomness and the absence of configurable parameters makes UCB very compelling. UCB is also very easy to understand, so let\u2019s just present the algorithm and then we can continue to discuss it in more detail."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "def ind_max(x):\n",
      "    m = max(x)\n",
      "    return x.index(m)\n",
      "\n",
      "class BernoulliArm():\n",
      "    def __init__(self, p):\n",
      "        self.p = p\n",
      "\n",
      "    def draw(self):\n",
      "        if random.random() > self.p:\n",
      "          return 0.0\n",
      "        else:\n",
      "          return 1.0\n",
      "        \n",
      "class UCB1():\n",
      "    def __init__(self, counts, v):\n",
      "        self.counts = counts\n",
      "        self.values = values\n",
      "        return\n",
      "\n",
      "    def initialize(self, n_arms):\n",
      "        self.counts = [0 for col in range(n_arms)]\n",
      "        self.values = [0.0 for col in range(n_arms)]\n",
      "        return\n",
      "\n",
      "    def select_arm(self):\n",
      "        n_arms = len(self.counts)\n",
      "        for arm in range(n_arms):\n",
      "          if self.counts[arm] == 0:\n",
      "            return arm\n",
      "\n",
      "        ucb_values = [0.0 for arm in range(n_arms)]\n",
      "        total_counts = sum(self.counts)\n",
      "        for arm in range(n_arms):\n",
      "          bonus = math.sqrt((2 * math.log(total_counts)) / float(self.counts[arm]))\n",
      "          ucb_values[arm] = self.values[arm] + bonus\n",
      "        return ind_max(ucb_values)\n",
      "\n",
      "    def update(self, chosen_arm, reward):\n",
      "        self.counts[chosen_arm] = self.counts[chosen_arm] + 1\n",
      "        n = self.counts[chosen_arm]\n",
      "    \n",
      "        value = self.values[chosen_arm]\n",
      "        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * reward\n",
      "        self.values[chosen_arm] = new_value\n",
      "        return"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###  This is a test suite \n",
      "\n",
      "def test_algorithm(algo, arms, num_sims, horizon):\n",
      "  chosen_arms = [0.0 for i in range(num_sims * horizon)]\n",
      "  rewards = [0.0 for i in range(num_sims * horizon)]\n",
      "  cumulative_rewards = [0.0 for i in range(num_sims * horizon)]\n",
      "  sim_nums = [0.0 for i in range(num_sims * horizon)]\n",
      "  times = [0.0 for i in range(num_sims * horizon)]\n",
      "\n",
      "  for sim in range(num_sims):\n",
      "    sim = sim + 1\n",
      "    algo.initialize(len(arms))\n",
      "\n",
      "    for t in range(horizon):\n",
      "      t = t + 1\n",
      "      index = (sim - 1) * horizon + t - 1\n",
      "      sim_nums[index] = sim\n",
      "      times[index] = t\n",
      "\n",
      "      chosen_arm = algo.select_arm()\n",
      "      chosen_arms[index] = chosen_arm\n",
      "\n",
      "      reward = arms[chosen_arms[index]].draw()\n",
      "      rewards[index] = reward\n",
      "\n",
      "      if t == 1:\n",
      "        cumulative_rewards[index] = reward\n",
      "      else:\n",
      "        cumulative_rewards[index] = cumulative_rewards[index - 1] + reward\n",
      "\n",
      "      algo.update(chosen_arm, reward)\n",
      "\n",
      "  return [sim_nums, times, chosen_arms, rewards, cumulative_rewards]\n",
      "\n",
      "\n",
      "\n",
      "import random\n",
      "\n",
      "# random.seed(1)\n",
      "# In this case we have 6 arms or 6 choice to choose. \n",
      "# 0.1 means we get a reward from arm 1 10% of the time\n",
      "# 0.4 means we get a reward from arm 2 40% of the time\n",
      "# The test code is basically doing simulations to find the best arm\n",
      "# In our case the best arm would be the best subject line \n",
      "\n",
      "\n",
      "means = [0.1, 0.4, 0.3, 0.8, 0.3, 0.9]\n",
      "n_arms = len(means)\n",
      "random.shuffle(means)\n",
      "arms = map(lambda (mu): BernoulliArm(mu), means)\n",
      "\n",
      "print arms\n",
      "print(\"Best arm is \" + str(ind_max(means)))\n",
      "\n",
      "algo = UCB1([], [])\n",
      "algo.initialize(n_arms)\n",
      "results = test_algorithm(algo, arms, 1000, 500)\n",
      "\n",
      "f = open(\"ucb1_results.tsv\", \"w\")\n",
      "\n",
      "for i in range(len(results[0])):\n",
      "  f.write(\"\\t\".join([str(results[j][i]) for j in range(len(results))]) + \"\\n\")\n",
      "\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[<__main__.BernoulliArm instance at 0x105ffcf38>, <__main__.BernoulliArm instance at 0x105f97e18>, <__main__.BernoulliArm instance at 0x105ffd248>, <__main__.BernoulliArm instance at 0x105ffd290>, <__main__.BernoulliArm instance at 0x105ffd200>, <__main__.BernoulliArm instance at 0x105ffd2d8>]\n",
        "Best arm is 3\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Recommedation \n",
      "\n",
      "> We probably want to explore Softmax and UCB1. The both work well in different scenarios. They both utilize a healthy exploration - exploitation balance and achieve convergence much faster \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}