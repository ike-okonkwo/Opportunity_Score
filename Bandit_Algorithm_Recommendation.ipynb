{
 "metadata": {
  "name": "",
  "signature": "sha256:34720e8e7d40943ab912690cce0fac64f129c78dc5b158a0744fc9126ee4df60"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Exploration - explotation technique\n",
      "\n",
      "- (1) they smoothly decrease the amount of exploring they do over time instead of requiring you to make a sudden jump and \n",
      "- (2) they focus your resources during exploration on the better options instead of wasting time on the inferior options that are over-explored during typical A/B testing\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Epsilion Greedy \n",
      "\n",
      "> The epsilon-Greedy algorithm explores by selecting from all of the arms completely at random. It makes one of these random exploratory decisions with probability epsilon\n",
      "\n",
      "- With probability 1 \u2013 epsilon, the epsilon-Greedy algorithm exploits the best known option.\n",
      "- With probability epsilon / 2, the epsilon-Greedy algorithm explores the best known option.\n",
      "- With probability epsilon / 2, the epsilon-Greedy algorithm explores the worst known option.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Softmax Annealing\n",
      "\n",
      "> The Softmax algorithm tries to cope with arms differing in estimated value by explicitly incorporating information about the reward rates of the available arms into its method for choosing which arm to select when it explores. The Softmax algorithm explores by randomly selecting from all of the available arms with probabilities that are more-or-less proportional to the estimated value of each of the arms. If the other arms are noticeably worse than the best arm, they\u2019re chosen with very low probability. If the arms all have similar values, they\u2019re each chosen nearly equally often."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 0
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "UCB1\n",
      "\n",
      "- The algorithm\u2019s default choice is to select the arm that currently has the highest estimated value.\n",
      "- The algorithm sometimes decides to explore and chooses an option that isn\u2019t the one that currently seems best:\n",
      "\n",
      "\n",
      "> UCB doesn\u2019t use randomness at all. Unlike epsilon-Greedy or Softmax, it\u2019s possible to know exactly how UCB will behave in any given situation. This can make it easier to reason about at times.\n",
      "UCB doesn\u2019t have any free parameters that you need to configure before you can deploy it. This is a major improvement if you\u2019re interested in running it in the wild, because it means that you can start to use UCB without having a clear sense of what you expect the world to behave like.\n",
      "Taken together, the use of an explicit measure of confidence, the absence of unnecessary randomness and the absence of configurable parameters makes UCB very compelling. UCB is also very easy to understand, so let\u2019s just present the algorithm and then we can continue to discuss it in more detail.\n",
      "\n",
      "> The answer is surprising and reveals why the curiosity bonus that UCB has can behave in an non-intuitive way: the little dips you see in this graph come from UCB backpedaling and experimenting with inferior arms because it comes to the conclusion that it knows too little about those arms. This backpedaling matters less and less over time, but it\u2019s always present in UCB\u2019s behavior, which means that UCB doesn\u2019t become a strictly greedy algorithm even if you have a huge amount of data.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to explicitly keeping track of our confidence in the estimated values of each arm, the UCB algorithm is special for two other reasons:\n",
      "UCB doesn\u2019t use randomness at all. Unlike epsilon-Greedy or Softmax, it\u2019s possible to know exactly how UCB will behave in any given situation. This can make it easier to reason about at times.\n",
      "UCB doesn\u2019t have any free parameters that you need to configure before you can deploy it. This is a major improvement if you\u2019re interested in running it in the wild, because it means that you can start to use UCB without having a clear sense of what you expect the world to behave like.\n",
      "Taken together, the use of an explicit measure of confidence, the absence of unnecessary randomness and the absence of configurable parameters makes UCB very compelling. UCB is also very easy to understand, so let\u2019s just present the algorithm and then we can continue to discuss it in more detail."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "import pandas as pd\n",
      "import math"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ind_max(x):\n",
      "    m = max(x)\n",
      "    return x.index(m)\n",
      "\n",
      "class BernoulliArm():\n",
      "    def __init__(self, p):\n",
      "        self.p = p\n",
      "\n",
      "    def draw(self):\n",
      "        if random.random() > self.p:\n",
      "          return 0.0\n",
      "        else:\n",
      "          return 1.0\n",
      "        \n",
      "class UCB1():\n",
      "    def __init__(self, counts, values):\n",
      "        self.counts = counts\n",
      "        self.values = values\n",
      "        return\n",
      "\n",
      "    def initialize(self, n_arms):\n",
      "        self.counts = [0 for col in range(n_arms)]\n",
      "        self.values = [0.0 for col in range(n_arms)]\n",
      "        return\n",
      "\n",
      "    def select_arm(self):\n",
      "        n_arms = len(self.counts)\n",
      "        for arm in range(n_arms):\n",
      "          if self.counts[arm] == 0:\n",
      "            return arm\n",
      "\n",
      "        ucb_values = [0.0 for arm in range(n_arms)]\n",
      "        total_counts = sum(self.counts)\n",
      "        for arm in range(n_arms):\n",
      "          bonus = math.sqrt((2 * math.log(total_counts)) / float(self.counts[arm]))\n",
      "          ucb_values[arm] = self.values[arm] + bonus\n",
      "        return ind_max(ucb_values)\n",
      "\n",
      "    def update(self, chosen_arm, reward):\n",
      "        self.counts[chosen_arm] = self.counts[chosen_arm] + 1\n",
      "        n = self.counts[chosen_arm]\n",
      "    \n",
      "        value = self.values[chosen_arm]\n",
      "        new_value = ((n - 1) / float(n)) * value + (1 / float(n)) * reward\n",
      "        self.values[chosen_arm] = new_value\n",
      "        return"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###  This is a test suite \n",
      "\n",
      "def test_algorithm(algo, arms, num_sims, horizon):\n",
      "  chosen_arms = [0.0 for i in range(num_sims * horizon)]\n",
      "  rewards = [0.0 for i in range(num_sims * horizon)]\n",
      "  cumulative_rewards = [0.0 for i in range(num_sims * horizon)]\n",
      "  sim_nums = [0.0 for i in range(num_sims * horizon)]\n",
      "  times = [0.0 for i in range(num_sims * horizon)]\n",
      "\n",
      "  for sim in range(num_sims):\n",
      "    sim = sim + 1\n",
      "    algo.initialize(len(arms))\n",
      "\n",
      "    for t in range(horizon):\n",
      "      t = t + 1\n",
      "      index = (sim - 1) * horizon + t - 1\n",
      "      sim_nums[index] = sim\n",
      "      times[index] = t\n",
      "\n",
      "      chosen_arm = algo.select_arm()\n",
      "      chosen_arms[index] = chosen_arm\n",
      "\n",
      "      reward = arms[chosen_arms[index]].draw()\n",
      "      rewards[index] = reward\n",
      "\n",
      "      if t == 1:\n",
      "        cumulative_rewards[index] = reward\n",
      "      else:\n",
      "        cumulative_rewards[index] = cumulative_rewards[index - 1] + reward\n",
      "\n",
      "      algo.update(chosen_arm, reward)\n",
      "\n",
      "  return [sim_nums, times, chosen_arms, rewards, cumulative_rewards]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- Recommedation \n",
      "\n",
      "> We probably want to explore Softmax and UCB1. The both work well in different scenarios. They both utilize a healthy exploration - exploitation balance and achieve convergence much faster \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### This generates mock subject line data with expected rewards (open : 1 / not opened : 2)\n",
      "\n",
      "# set random seed\n",
      "random.seed(5)\n",
      "\n",
      "# we are assuming we start with 6 different subject lines. \n",
      "# The goal here here will be to get to the best subject line and then stick\n",
      "# with that subject line for subsequent campaigns\n",
      "\n",
      "random_title = ['subject_line_1','subject_line_2','subject_line_3','subject_line_4',\n",
      "                'subject_line_5','subject_line_6']\n",
      "\n",
      "index = range(len(random_title))\n",
      "\n",
      "# Generate sequence of Campaign subject lines and expected rewards\n",
      "# The reward is 1 if the email is opened and 0 if the email wasn't opened\n",
      "\n",
      "df = pd.DataFrame() \n",
      "\n",
      "sim_count = 1000 # We assume that we send sim_count eamils the first day\n",
      "\n",
      "for i in range(sim_count):\n",
      "    j = random.choice(index)\n",
      "    data = (random_title[j],random.randint(0,1)) # generate subject line and expected reward\n",
      "    datd_df = pd.DataFrame(list(data))\n",
      "    df = pd.concat([df,datd_df.transpose()], ignore_index=True)\n",
      "\n",
      "# Mock generated subject lines. \n",
      "# Each tuple has a subject lines and expected reward \n",
      "# When we put this in production their is going to be a cold start problem\n",
      "# because at the beginning of a campaign we don't have any data to start with\n",
      "# This simulated what would happen at the end of the first day\n",
      "# '''\n",
      "# ('subject_line_4', 1)\n",
      "# ('subject_line_5', 1)\n",
      "# ('subject_line_5', 1)\n",
      "# ('subject_line_1', 0)\n",
      "# ('subject_line_6', 1)\n",
      "# ('subject_line_6', 0)\n",
      "# ('subject_line_3', 0)\n",
      "# ('subject_line_4', 1)\n",
      "# ('subject_line_1', 0)\n",
      "# ('subject_line_2', 1)\n",
      "# ('subject_line_5', 0)\n",
      "# ('subject_line_5', 0)\n",
      "# ('subject_line_4', 0)\n",
      "# ('subject_line_1', 1)\n",
      "# ('subject_line_2', 0)\n",
      "# ('subject_line_6', 1)\n",
      "# ('subject_line_2', 1)\n",
      "# ('subject_line_4', 1)\n",
      "# ('subject_line_2', 1)\n",
      "# ('subject_line_5', 1)\n",
      "# ('subject_line_6', 0)\n",
      "# ('subject_line_3', 0)\n",
      "# '''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cols = ['Subject_line', 'Reward']\n",
      "df.columns = cols"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_reward_pos = df[df['Reward'] == 1]\n",
      "agg = df_reward_pos.groupby(by=('Subject_line')).sum().sort('Reward', ascending = False)\n",
      "agg['means'] = agg['Reward']/sim_count\n",
      "\n",
      "agg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Reward</th>\n",
        "      <th>means</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Subject_line</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>subject_line_5</th>\n",
        "      <td> 90</td>\n",
        "      <td> 0.090</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>subject_line_3</th>\n",
        "      <td> 84</td>\n",
        "      <td> 0.084</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>subject_line_4</th>\n",
        "      <td> 83</td>\n",
        "      <td> 0.083</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>subject_line_6</th>\n",
        "      <td> 78</td>\n",
        "      <td> 0.078</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>subject_line_1</th>\n",
        "      <td> 77</td>\n",
        "      <td> 0.077</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>subject_line_2</th>\n",
        "      <td> 70</td>\n",
        "      <td> 0.070</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "                Reward  means\n",
        "Subject_line                 \n",
        "subject_line_5      90  0.090\n",
        "subject_line_3      84  0.084\n",
        "subject_line_4      83  0.083\n",
        "subject_line_6      78  0.078\n",
        "subject_line_1      77  0.077\n",
        "subject_line_2      70  0.070"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim_means = []\n",
      "\n",
      "for i in range(len(agg)):\n",
      "    sim_means.append(agg['means'][i])\n",
      "    print agg['means'][i],\n",
      "    \n",
      "print \n",
      "print sim_means\n",
      "print agg.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.09 0.084 0.083 0.078 0.077 0.07\n",
        "[0.089999999999999997, 0.084000000000000005, 0.083000000000000004, 0.078, 0.076999999999999999, 0.070000000000000007]\n",
        "Index([u'subject_line_5', u'subject_line_3', u'subject_line_4', u'subject_line_6', u'subject_line_1', u'subject_line_2'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "random.seed(1)\n",
      "# In this case we have 6 arms or 6 choice to choose. \n",
      "# 0.1 means we get a reward from arm 1 10% of the time\n",
      "# 0.4 means we get a reward from arm 2 40% of the time\n",
      "# The test code is basically doing simulations to find the best arm\n",
      "# In our case the best arm would be the best subject line \n",
      "\n",
      "\n",
      "means = [0.1, 0.4, 0.3, 0.8, 0.3, 0.9]\n",
      "# replace means by sim_means\n",
      "n_arms = len(sim_means)\n",
      "random.shuffle(sim_means)\n",
      "arms = map(lambda (mu): BernoulliArm(mu), sim_means)\n",
      "\n",
      "print(\"Best arm is \" + str(ind_max(sim_means)))\n",
      "print(\"Best subject line is\" + agg.index[ind_max(sim_means)] ) \n",
      "\n",
      "algo = UCB1([], [])\n",
      "algo.initialize(n_arms)\n",
      "results = test_algorithm(algo, arms, 1000, 500)\n",
      "\n",
      "f = open(\"ucb1_results.tsv\", \"w\")  # this file will hold the simulated results from ucb1\n",
      "for i in range(len(results[0])):\n",
      "  f.write(\"\\t\".join([str(results[j][i]) for j in range(len(results))]) + \"\\n\")\n",
      "\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best arm is 5\n",
        "Best subject line issubject_line_2\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Convergence of Results "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Convergence for the Armed Bandit Algorithm can be determined in the following ways\n",
      "\n",
      "- Tracking the probability of choosign the best arm \n",
      "- Tracking the average reward at each point in time\n",
      "- Traking the cumulative reward at each point in time\n",
      "\n",
      "In our case we will be using the second approach and tthird approach which are to track the average reward and the cumulative reward at each point in time. This will give us more visibility into the best performing arms within a campaign "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = pd.read_csv('ucb1_results.tsv', sep='\\t', names=['sim_nums', 'times', 'chosen_arms', 'rewards', 'cumulative_rewards'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res.head(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>sim_nums</th>\n",
        "      <th>times</th>\n",
        "      <th>chosen_arms</th>\n",
        "      <th>rewards</th>\n",
        "      <th>cumulative_rewards</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 1</td>\n",
        "      <td>   1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 1</td>\n",
        "      <td>   2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 1</td>\n",
        "      <td>   3</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 1</td>\n",
        "      <td>   4</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 1</td>\n",
        "      <td>   5</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td>  1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 1</td>\n",
        "      <td>   6</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td>  1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 1</td>\n",
        "      <td>   7</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td>  1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 1</td>\n",
        "      <td>   8</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 1</td>\n",
        "      <td>   9</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>  2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 1</td>\n",
        "      <td>  10</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td>  2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 1</td>\n",
        "      <td>  11</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td>  2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 1</td>\n",
        "      <td>  12</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td>  2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 1</td>\n",
        "      <td>  13</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 1</td>\n",
        "      <td>  14</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td>  2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 1</td>\n",
        "      <td>  15</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>  3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15</th>\n",
        "      <td> 1</td>\n",
        "      <td>  16</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td>  4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16</th>\n",
        "      <td> 1</td>\n",
        "      <td>  17</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17</th>\n",
        "      <td> 1</td>\n",
        "      <td>  18</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td>  4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18</th>\n",
        "      <td> 1</td>\n",
        "      <td>  19</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19</th>\n",
        "      <td> 1</td>\n",
        "      <td>  20</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td>  4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20</th>\n",
        "      <td> 1</td>\n",
        "      <td>  21</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td>  4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21</th>\n",
        "      <td> 1</td>\n",
        "      <td>  22</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td>  5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22</th>\n",
        "      <td> 1</td>\n",
        "      <td>  23</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23</th>\n",
        "      <td> 1</td>\n",
        "      <td>  24</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24</th>\n",
        "      <td> 1</td>\n",
        "      <td>  25</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25</th>\n",
        "      <td> 1</td>\n",
        "      <td>  26</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26</th>\n",
        "      <td> 1</td>\n",
        "      <td>  27</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27</th>\n",
        "      <td> 1</td>\n",
        "      <td>  28</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28</th>\n",
        "      <td> 1</td>\n",
        "      <td>  29</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29</th>\n",
        "      <td> 1</td>\n",
        "      <td>  30</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>70</th>\n",
        "      <td> 1</td>\n",
        "      <td>  71</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>71</th>\n",
        "      <td> 1</td>\n",
        "      <td>  72</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>72</th>\n",
        "      <td> 1</td>\n",
        "      <td>  73</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>73</th>\n",
        "      <td> 1</td>\n",
        "      <td>  74</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>74</th>\n",
        "      <td> 1</td>\n",
        "      <td>  75</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75</th>\n",
        "      <td> 1</td>\n",
        "      <td>  76</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>76</th>\n",
        "      <td> 1</td>\n",
        "      <td>  77</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>77</th>\n",
        "      <td> 1</td>\n",
        "      <td>  78</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>78</th>\n",
        "      <td> 1</td>\n",
        "      <td>  79</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>79</th>\n",
        "      <td> 1</td>\n",
        "      <td>  80</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>80</th>\n",
        "      <td> 1</td>\n",
        "      <td>  81</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>81</th>\n",
        "      <td> 1</td>\n",
        "      <td>  82</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>82</th>\n",
        "      <td> 1</td>\n",
        "      <td>  83</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>83</th>\n",
        "      <td> 1</td>\n",
        "      <td>  84</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>84</th>\n",
        "      <td> 1</td>\n",
        "      <td>  85</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>85</th>\n",
        "      <td> 1</td>\n",
        "      <td>  86</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td>  9</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>86</th>\n",
        "      <td> 1</td>\n",
        "      <td>  87</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>87</th>\n",
        "      <td> 1</td>\n",
        "      <td>  88</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>88</th>\n",
        "      <td> 1</td>\n",
        "      <td>  89</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>89</th>\n",
        "      <td> 1</td>\n",
        "      <td>  90</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>90</th>\n",
        "      <td> 1</td>\n",
        "      <td>  91</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>91</th>\n",
        "      <td> 1</td>\n",
        "      <td>  92</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>92</th>\n",
        "      <td> 1</td>\n",
        "      <td>  93</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>93</th>\n",
        "      <td> 1</td>\n",
        "      <td>  94</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>94</th>\n",
        "      <td> 1</td>\n",
        "      <td>  95</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 10</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>95</th>\n",
        "      <td> 1</td>\n",
        "      <td>  96</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 11</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>96</th>\n",
        "      <td> 1</td>\n",
        "      <td>  97</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 11</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>97</th>\n",
        "      <td> 1</td>\n",
        "      <td>  98</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "      <td> 11</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>98</th>\n",
        "      <td> 1</td>\n",
        "      <td>  99</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td> 11</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>99</th>\n",
        "      <td> 1</td>\n",
        "      <td> 100</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 11</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>100 rows \u00d7 5 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "    sim_nums  times  chosen_arms  rewards  cumulative_rewards\n",
        "0          1      1            0        0                   0\n",
        "1          1      2            1        0                   0\n",
        "2          1      3            2        0                   0\n",
        "3          1      4            3        0                   0\n",
        "4          1      5            4        1                   1\n",
        "5          1      6            5        0                   1\n",
        "6          1      7            4        0                   1\n",
        "7          1      8            0        0                   1\n",
        "8          1      9            1        1                   2\n",
        "9          1     10            2        0                   2\n",
        "10         1     11            3        0                   2\n",
        "11         1     12            5        0                   2\n",
        "12         1     13            1        0                   2\n",
        "13         1     14            4        0                   2\n",
        "14         1     15            1        1                   3\n",
        "15         1     16            4        1                   4\n",
        "16         1     17            1        0                   4\n",
        "17         1     18            4        0                   4\n",
        "18         1     19            0        0                   4\n",
        "19         1     20            2        0                   4\n",
        "20         1     21            3        0                   4\n",
        "21         1     22            5        1                   5\n",
        "22         1     23            5        0                   5\n",
        "23         1     24            1        0                   5\n",
        "24         1     25            4        0                   5\n",
        "25         1     26            5        0                   5\n",
        "26         1     27            0        0                   5\n",
        "27         1     28            2        0                   5\n",
        "28         1     29            3        0                   5\n",
        "29         1     30            1        0                   5\n",
        "..       ...    ...          ...      ...                 ...\n",
        "70         1     71            4        0                   9\n",
        "71         1     72            5        0                   9\n",
        "72         1     73            0        0                   9\n",
        "73         1     74            2        0                   9\n",
        "74         1     75            3        0                   9\n",
        "75         1     76            1        0                   9\n",
        "76         1     77            4        0                   9\n",
        "77         1     78            5        0                   9\n",
        "78         1     79            0        0                   9\n",
        "79         1     80            2        0                   9\n",
        "80         1     81            3        0                   9\n",
        "81         1     82            1        0                   9\n",
        "82         1     83            4        0                   9\n",
        "83         1     84            5        0                   9\n",
        "84         1     85            1        0                   9\n",
        "85         1     86            4        0                   9\n",
        "86         1     87            0        1                  10\n",
        "87         1     88            0        0                  10\n",
        "88         1     89            0        0                  10\n",
        "89         1     90            2        0                  10\n",
        "90         1     91            3        0                  10\n",
        "91         1     92            5        0                  10\n",
        "92         1     93            1        0                  10\n",
        "93         1     94            4        0                  10\n",
        "94         1     95            0        0                  10\n",
        "95         1     96            5        1                  11\n",
        "96         1     97            5        0                  11\n",
        "97         1     98            2        0                  11\n",
        "98         1     99            3        0                  11\n",
        "99         1    100            5        0                  11\n",
        "\n",
        "[100 rows x 5 columns]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Cumulative Reward for each arm at any given point"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# As an exmple, we will be taking a sample of the first 20K instances / results from MAB\n",
      "# In productionm the code below could just be a function that recalculates the cumulative\n",
      "# reward for each arm\n",
      "\n",
      "test_res = res.head(2000000)\n",
      "print len(test_res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "500000\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cum_rewards = []\n",
      "\n",
      "# get the unique list of arms the system has seen so far\n",
      "arms = list(res.chosen_arms.unique())\n",
      "\n",
      "# initial cumulative rewards for each arms \n",
      "for i in range(len(arms)):\n",
      "    cum_rewards.append(0)\n",
      "\n",
      "print 'cumulative score--start'\n",
      "print cum_rewards\n",
      "\n",
      "# calulate the cumulative reward for each arms . This is happening in batch here but it would \n",
      "# typically occur after each arm is pulled\n",
      "\n",
      "for i in range(len(test_res)):\n",
      "    cum_rewards[res.chosen_arms.ix[i]] += res.rewards.ix[i]\n",
      "    \n",
      "print 'cumulative score--end'\n",
      "print cum_rewards,\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cumulative score--start\n",
        "[0, 0, 0, 0, 0, 0]\n",
        "cumulative score--end"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[7173.0, 6906.0, 5472.0, 6407.0, 6453.0, 7751.0]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# typical the cumulative reward should be recalculated after the each arm-pull\n",
      "for i in range(len(cum_rewards)):\n",
      "    print 'subject_line - %d : %4.3f'%(cum_rewards.index((sorted(cum_rewards, reverse=True))[i]),sorted(cum_rewards, reverse=True)[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "subject_line - 5 : 7751.000\n",
        "subject_line - 0 : 7173.000\n",
        "subject_line - 1 : 6906.000\n",
        "subject_line - 4 : 6453.000\n",
        "subject_line - 3 : 6407.000\n",
        "subject_line - 2 : 5472.000\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Average Reward for each arm at any given point"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# populate the reward per arm after each arm pull\n",
      "# Use the first 33 milllion simulations  \n",
      "\n",
      "test_res = res.head(2000000)\n",
      "\n",
      "print len(test_res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "500000\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# setup test reward senarios for wach of the arms\n",
      "arms = list(res.chosen_arms.unique())\n",
      "\n",
      "avg_reward_dict = {}\n",
      "\n",
      "# seed the dict with null lists\n",
      "for i in arms:\n",
      "    avg_reward_dict[i] = []\n",
      "\n",
      "for i in range(len(test_res)):\n",
      "    avg_reward_dict[test_res.chosen_arms.ix[i]].append(test_res.rewards.ix[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_reward_list = []\n",
      "\n",
      "# calulate the average reward for each arms . This is happening in batch here but it would typically \n",
      "# occur after each arm is pulled\n",
      "for key, value in avg_reward_dict.iteritems():\n",
      "    avg_reward_list.append(np.mean(value))\n",
      "    \n",
      "print avg_reward_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.084313840728768727, 0.082094076530794188, 0.069314957438184027, 0.077841765077513725, 0.078219129928847622, 0.089039758302604216]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# top performing subject lines by average reward \n",
      "for i in range(len(avg_reward_list)):\n",
      "    print 'subject_line - %d : %4.3f'%(avg_reward_list.index((sorted(avg_reward_list, reverse=True))[i]),sorted(avg_reward_list, reverse=True)[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "subject_line - 5 : 0.089\n",
        "subject_line - 0 : 0.084\n",
        "subject_line - 1 : 0.082\n",
        "subject_line - 4 : 0.078\n",
        "subject_line - 3 : 0.078\n",
        "subject_line - 2 : 0.069\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Looking at both options for determining convergence, we can esee that there is greater separation between the arms when we use cumulative rewards over time as our metric for convergence compared to when we use average reward over tine "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Optimizing for Email Send Load  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- We will determine the optimai send load to achieve convergebce via Monte Carlo simulations\n",
      "- How many email do we need to send to guarantee convergence\n",
      "- We will basically be fitting a log-normal distribution to our calculated email numbers to determine the minimum bound of the \n",
      "- number of emails we should send to guarantee convergence "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random \n",
      "from scipy.stats import norm, lognorm\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy import stats # Import the scipy.stats module\n",
      "\n",
      "def email_send_num_monte_carlo(weekly_email_volume):\n",
      "    # num_subject_lines\n",
      "    \n",
      "    '''\n",
      "    (int, int) -> (int)\n",
      "    \n",
      "    This function takes as input the number of email to be sent for a campaign in a given week\n",
      "    and it returns the lower bound of the number of email that will have to be send to \n",
      "    start seeing some convergence effects\n",
      "    \n",
      "    This is a first cut and is based on results from a Monte Carlo simulation. Over time, we should be able to use\n",
      "    real data for this to achieve more accurate estimates \n",
      "    '''\n",
      "\n",
      "    # observed from converage by average reward graph\n",
      "    convergence = [x/1000. for x in range(100, 900)]\n",
      "\n",
      "    # range of open rates from 0% to 50%\n",
      "    campaign_global_open_rate = [x/100. for x in range(50)]\n",
      "    \n",
      "    # create list to hold all the simulated results for email volume to guarantee convergence as determined by the \n",
      "    # monte carlo simulation\n",
      "    campaign_monte_carlo = []\n",
      "\n",
      "    # Monte Carlo Simulations\n",
      "    # run through 2 million simulation scenarios to build a distribution of the volume needed for convergence\n",
      "    for i in xrange(5000):\n",
      "        campaign_monte_carlo.extend([weekly_email_volume * random.choice(campaign_global_open_rate) * random.choice(convergence) \n",
      "                       for i in range(weekly_email_volume)])\n",
      "    \n",
      "    ######  PLOT histogram  --   not needed for prod \n",
      "    n, bins, patches = plt.hist(sorted(campaign_monte_carlo)[5000:], bins=200, normed=True) # Plot histogram\n",
      "\n",
      "    # Fit lognormal distribution to calculated email load data \n",
      "    shape, loc, scale = stats.lognorm.fit(sorted(campaign_monte_carlo)[5000:], floc=0)\n",
      "    mu = np.log(scale) # Mean of log(X)\n",
      "    sigma = shape # Standard deviation of log(X)\n",
      "    M = np.exp(mu) # Geometric mean == median\n",
      "    s = np.exp(sigma) # Geometric standard deviation\n",
      "    \n",
      "    ######  PLOT fitted distribution  -- not needed for prod \n",
      "    x = np.linspace((np.array(campaign_monte_carlo)).min(), (np.array(campaign_monte_carlo)).max(), num=400)\n",
      "    plt.plot(x, stats.lognorm.pdf(x, shape, loc=0, scale=scale), 'r', linewidth=3) # Plot fitted curve\n",
      "    ax = plt.gca() # Get axis handle for text positioning\n",
      "    txt = plt.text(0.9, 0.9, 'M = %.2f\\ns = %.2f' % (M, s), horizontalalignment='right', \n",
      "                    size='large', verticalalignment='top', transform=ax.transAxes)\n",
      "\n",
      "    # returm the mean + 2*standard deviations\n",
      "    print 'If the total weekly volume for a campaign in %d emails, we need to see results back from at least %d emails to start seeing convergence effects' %(weekly_email_volume,int(M + (2*s)) ) \n",
      "                                                                                                                                                      \n",
      "    return int(M + (2*s))\n",
      "\n",
      "## If the email load for a week is 1000, we will need to send at least 88 emails to start seeing convergence effects\n",
      "email_send_num_monte_carlo(1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "If the total weekly volume for a campaign in 1000 emails, we need to see results back from at least 88 emails to start seeing convergence effects\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "88"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1078f6e50>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we're basically fitting a probability distribution to the data generated by the Monte Carlo simulation and then arriving at the lower bound of results we need to receive to start seeing convergence effects for the arms"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will be using a simple linear function for this instead "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calc_num_convergence(total_email_count, num_days, num_subject_lines):\n",
      "    '''\n",
      "    (int, int, int) -> (int)\n",
      "    Returns the lower bound of the number of emails that need to be sent to \n",
      "    see convergence effects\n",
      "    \n",
      "    calc_num_convergence(100, 2, 4) -> 12\n",
      "    calc_num_convergence(200, 2, 3) -> 67\n",
      "    calc_num_convergence(300, 2, 5) -> 64\n",
      "    calc_num_convergence(150, 2, 6) -> 14\n",
      "    \n",
      "    '''\n",
      "    \n",
      "    daily_count_per_subject_line = total_email_count / (num_days * num_subject_lines)\n",
      "\n",
      "    ucb_convergence_constant = 0.8\n",
      "    \n",
      "    if num_subject_lines <= 2 or num_subject_lines > 5:\n",
      "        return daily_count_per_subject_line\n",
      "    else:\n",
      "        return int((np.sum(range(1, daily_count_per_subject_line, num_subject_lines)[-num_subject_lines:])) * ucb_convergence_constant) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "calc_num_convergence(100, 2, 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 187,
       "text": [
        "12"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "calc_num_convergence(200, 2, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 188,
       "text": [
        "67"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "calc_num_convergence(300, 2, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 189,
       "text": [
        "64"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "calc_num_convergence(150, 2, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 185,
       "text": [
        "14"
       ]
      }
     ],
     "prompt_number": 185
    }
   ],
   "metadata": {}
  }
 ]
}